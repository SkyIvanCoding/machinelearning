{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parwinderau/machinelearning/blob/main/CNN_getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example modified from the blog: https://victorzhou.com/blog/keras-cnn-tutorial/\n",
        "\n",
        "# A starting example on CNN using Keras\n",
        "\n",
        "# firstly we import the dataset from the MNIST database. The database has been created in 1998 and collects several handwritten pictures, already scaled and centered for\n",
        "# ML applications. The database can be loaded from Keras. http://yann.lecun.com/exdb/mnist/ \n",
        "\n",
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "CL3V7_FsbZ_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fc6d42-36f7-44b5-946b-1f1033c1669c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale all the images (Normalisation) such that their values are between 0 and 1\n",
        "# Check why between -0.5 and 0.5\n",
        "print (train_images[0])\n",
        "train_images = (train_images / 255)\n",
        "test_images = (test_images / 255)"
      ],
      "metadata": {
        "id": "mcpPGy3feJs_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# The images are 28 x 28 but Keras needs 28 x 28 x 1\n",
        "\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)"
      ],
      "metadata": {
        "id": "LkVMiAUSeVYM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Model Cell\n",
        "#\n",
        "\n",
        "\n",
        "# how many types of filters\n",
        "num_filters = 6\n",
        "\n",
        "# size of each filter 3x3\n",
        "filter_size = 3\n",
        "\n",
        "# pooling size is the pooling size (often 2x2 works fine)\n",
        "ps = 2\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "\n",
        "# Build the model.\n",
        "model = Sequential([\n",
        "  # basic convolutional layer \n",
        "  Conv2D(num_filters, filter_size, activation='tanh',input_shape=(28, 28, 1)),\n",
        "  # max pooling layer\n",
        "  MaxPooling2D(pool_size = ps),\n",
        "  # flattening process\n",
        "  Flatten(),\n",
        "  # fully connected final layer (10 are the possible classes)\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n"
      ],
      "metadata": {
        "id": "XBwCE4zTkqq5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation of the model through compilation\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Train the compiled model model\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=20,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")\n",
        "\n",
        "# Save the model to disk.\n",
        "model.save_weights('cnn.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRtMo0c7k-cz",
        "outputId": "1f2a3a5a-d29f-4e5d-85c9-f4259b7bd621"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0785 - accuracy: 0.9772 - val_loss: 0.0869 - val_accuracy: 0.9734\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0742 - accuracy: 0.9779 - val_loss: 0.0849 - val_accuracy: 0.9748\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0711 - accuracy: 0.9785 - val_loss: 0.0850 - val_accuracy: 0.9738\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0674 - accuracy: 0.9801 - val_loss: 0.0885 - val_accuracy: 0.9729\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0661 - accuracy: 0.9804 - val_loss: 0.0833 - val_accuracy: 0.9747\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0621 - accuracy: 0.9818 - val_loss: 0.0787 - val_accuracy: 0.9753\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0605 - accuracy: 0.9817 - val_loss: 0.0817 - val_accuracy: 0.9763\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0582 - accuracy: 0.9821 - val_loss: 0.0815 - val_accuracy: 0.9758\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0561 - accuracy: 0.9830 - val_loss: 0.0822 - val_accuracy: 0.9757\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 0.0869 - val_accuracy: 0.9753\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0529 - accuracy: 0.9841 - val_loss: 0.0791 - val_accuracy: 0.9765\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.0864 - val_accuracy: 0.9744\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.0847 - val_accuracy: 0.9746\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 0.0807 - val_accuracy: 0.9773\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0469 - accuracy: 0.9863 - val_loss: 0.0815 - val_accuracy: 0.9753\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.0810 - val_accuracy: 0.9763\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.0846 - val_accuracy: 0.9749\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0440 - accuracy: 0.9865 - val_loss: 0.0858 - val_accuracy: 0.9750\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0420 - accuracy: 0.9871 - val_loss: 0.0823 - val_accuracy: 0.9762\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0416 - accuracy: 0.9874 - val_loss: 0.0859 - val_accuracy: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xUgkWMUcW-gy"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# We load the model again so we do not need to train every time. This because the training process can \n",
        "# also be very long, especially if we want to train for many epochs.\n",
        "# Of course if we change something in the model, a new trainining is necessary.\n",
        "#\n",
        "\n",
        "def test_function(f_test_im):\n",
        "  model.load_weights('cnn.h5')\n",
        "\n",
        "  # Predict on the some of the images.\n",
        "  s_test_image = 50;\n",
        "  e_test_image = 250;\n",
        "\n",
        "  predictions = model.predict(f_test_im[s_test_image:e_test_image])\n",
        "\n",
        "  # Print our model's predictions.\n",
        "  pred = np.argmax(predictions, axis=1)\n",
        "  print('prediction = ', np.argmax(predictions, axis=1)) \n",
        "  print(' ')\n",
        "  exp = test_labels[s_test_image:e_test_image]\n",
        "\n",
        "  # Check our predictions against the ground truths.\n",
        "  print('expected label = ', test_labels[s_test_image:e_test_image])\n",
        "  print(' ')\n",
        "  res = pred - exp\n",
        "\n",
        "  # print(\"difference = \", pred - exp)\n",
        "  counter = 0\n",
        "  for i in res:\n",
        "    if i != 0:\n",
        "      counter+=1\n",
        "\n",
        "  print(\"test error = \", counter / (e_test_image - s_test_image) * 100, \"%\")\n",
        "\n",
        "  #  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_function(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HOaMYGtBeBM",
        "outputId": "7e295cd7-8c29-4834-d12d-efaf4f170222"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 6ms/step\n",
            "prediction =  [6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7\n",
            " 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6\n",
            " 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 9 9 9 5 5 1 5 6 0 3 4 4\n",
            " 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
            " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 3 2 7 1 2 8 4 1 7 3 3 8 8 7\n",
            " 9 2 2 4 1 5 9 8 7 2 3 0 6 4 2]\n",
            " \n",
            "expected label =  [6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7\n",
            " 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6\n",
            " 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4\n",
            " 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
            " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7\n",
            " 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2]\n",
            " \n",
            "test error =  1.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Try here to create your CNN\n",
        "# \n",
        "# Taking inspiration by the Model Cell Try to change the filters numer (increase and decrease)\n",
        "# or to create multiple Conv2D layers and \n",
        "# make different tests to see how the quality of the prediction changes according to the parameters.\n",
        "# You can also try to increase the epochs if you have time.\n",
        "#\n",
        "# [...]\n",
        "#"
      ],
      "metadata": {
        "id": "n8R_t7LH-10h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_function(test_images)"
      ],
      "metadata": {
        "id": "3h5oM9ybDXDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cfc157-4e0b-403a-f7d9-f165a5067067"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 5ms/step\n",
            "prediction =  [6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7\n",
            " 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6\n",
            " 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 9 9 9 5 5 1 5 6 0 3 4 4\n",
            " 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
            " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 3 2 7 1 2 8 4 1 7 3 3 8 8 7\n",
            " 9 2 2 4 1 5 9 8 7 2 3 0 6 4 2]\n",
            " \n",
            "expected label =  [6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7\n",
            " 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6\n",
            " 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4\n",
            " 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
            " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7\n",
            " 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2]\n",
            " \n",
            "test error =  1.5 %\n"
          ]
        }
      ]
    }
  ]
}